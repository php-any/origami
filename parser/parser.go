package parser

import (
	"errors"
	"fmt"
	"os"
	"strings"

	"github.com/php-any/origami/data"

	"github.com/php-any/origami/lexer"
	"github.com/php-any/origami/node"
	"github.com/php-any/origami/token"
)

// Parser è¡¨ç¤ºè§£æå™¨
type Parser struct {
	vm               data.VM
	source           *string
	lexer            *lexer.Lexer      // è¯æ³•åˆ†æå™¨
	tokens           []lexer.Token     // è¯æ³•å•å…ƒåˆ—è¡¨
	position         int               // å½“å‰å¤„ç†ä½ç½®
	errors           []data.Control    // é”™è¯¯åˆ—è¡¨
	scopeManager     *ScopeManager     // ä½œç”¨åŸŸç®¡ç†å™¨
	expressionParser *ExpressionParser // è¡¨è¾¾å¼è§£æå™¨

	identTryString bool

	namespace        *node.Namespace
	uses             map[string]string // ç±»å¼•ç”¨
	classPathManager ClassPathManager  // ç±»è·¯å¾„ç®¡ç†å™¨
}

// NewParser åˆ›å»ºä¸€ä¸ªæ–°çš„è§£æå™¨
func NewParser() *Parser {
	p := &Parser{
		lexer:            lexer.NewLexer(),
		tokens:           make([]lexer.Token, 0),
		position:         0,
		errors:           make([]data.Control, 0),
		scopeManager:     NewScopeManager(),
		uses:             make(map[string]string),
		classPathManager: NewDefaultClassPathManager(),
	}
	p.AddScanNamespace("app", "./")
	p.expressionParser = NewExpressionParser(p)
	return p
}

// reset é‡ç½®è§£æå™¨çŠ¶æ€
func (p *Parser) reset() {
	p.tokens = make([]lexer.Token, 0)
	p.position = 0
	p.errors = make([]data.Control, 0)
	p.uses = make(map[string]string)
	p.namespace = nil
	p.scopeManager = NewScopeManager()
}

func (p *Parser) Clone() *Parser {
	// åˆ›å»ºæ–°çš„è§£æå™¨å®ä¾‹
	cloned := &Parser{
		vm:               p.vm,             // VM æ˜¯å…±äº«çš„ï¼Œä¸éœ€è¦å…‹éš†
		source:           nil,              // å­—ç¬¦ä¸²æŒ‡é’ˆï¼Œå…±äº«å³å¯
		lexer:            lexer.NewLexer(), // åˆ›å»ºæ–°çš„è¯æ³•åˆ†æå™¨
		tokens:           make([]lexer.Token, 0),
		position:         0,
		errors:           make([]data.Control, 0),
		scopeManager:     NewScopeManager(),  // åˆ›å»ºæ–°çš„ä½œç”¨åŸŸç®¡ç†å™¨
		expressionParser: p.expressionParser, // ç¨åè®¾ç½®
		identTryString:   p.identTryString,
		namespace:        p.namespace, // å‘½åç©ºé—´èŠ‚ç‚¹ï¼Œå…±äº«å³å¯
		uses:             make(map[string]string),
		classPathManager: p.classPathManager, // ç±»è·¯å¾„ç®¡ç†å™¨æ˜¯å…±äº«çš„
	}
	cloned.expressionParser = NewExpressionParser(cloned)
	return cloned
}

func (p *Parser) SetVM(vm data.VM) {
	p.vm = vm
}

// ParseFile è§£ææ–‡ä»¶
func (p *Parser) ParseFile(filename string) (*node.Program, data.Control) {
	// è¯»å–æ–‡ä»¶å†…å®¹
	content, err := os.ReadFile(filename)
	if err != nil {
		return nil, data.NewErrorThrow(nil, err)
	}

	// é‡ç½®è§£æå™¨çŠ¶æ€
	p.reset()

	p.source = &filename
	// è¿›è¡Œåˆ†è¯
	p.tokens = p.lexer.Tokenize(string(content))

	// è§£æç¨‹åº
	program, acl := p.parseProgram()
	if acl != nil {
		return nil, acl
	}

	return program, nil
}

// parseProgram è§£æç¨‹åº
func (p *Parser) parseProgram() (*node.Program, data.Control) {
	statements := make([]data.GetValue, 0)

	last := 0
	// è§£ææ‰€æœ‰è¯­å¥
	for !p.isEOF() {
		stmt, acl := p.parseStatement()
		if acl != nil {
			return nil, acl
		}
		if stmt != nil {
			if n, ok := stmt.(*node.Namespace); ok {
				p.namespace = n
				statements = append(statements, stmt)
			} else {
				if n, ok := stmt.(*node.UseStatement); ok {
					p.uses[n.Alias] = n.Namespace
					continue
				}

				if p.namespace != nil {
					p.namespace.Statements = append(p.namespace.Statements, stmt)
				} else {
					statements = append(statements, stmt)
				}
			}
		} else if p.position != last {
			last = p.position
		} else {
			return nil, data.NewErrorThrow(p.newFrom(), errors.New("æ— æ³•è¯†åˆ«è¯­å¥"))
		}
	}

	return node.NewProgram(nil, statements), nil
}

// current è¿”å›å½“å‰è¯æ³•å•å…ƒ
func (p *Parser) current() lexer.Token {
	if p.position >= len(p.tokens) {
		return lexer.Token{Type: token.EOF}
	}
	return p.tokens[p.position]
}

// peek å‘å‰æŸ¥çœ‹æŒ‡å®šä½ç½®çš„token
func (p *Parser) peek(offset int) lexer.Token {
	pos := p.position + offset
	if pos >= len(p.tokens) {
		return lexer.Token{Type: token.EOF}
	}
	return p.tokens[pos]
}

// æ£€æŸ¥åç»­å•è¯çš„å¯èƒ½ç±»å‹
func (p *Parser) checkPositionIs(position int, checks ...token.TokenType) bool {
	if len(checks) == 1 && checks[0] == token.EOF {
		if p.position+position >= len(p.tokens) {
			return true
		}
		for _, check := range checks {
			if p.tokens[p.position+position].Type == check {
				return true
			}
		}
	} else {
		if p.position+position >= len(p.tokens) {
			return false
		}
	}

	for _, check := range checks {
		if p.tokens[p.position+position].Type == check {
			return true
		}
	}
	return false
}

func (p *Parser) currentIsTypeOrEOF(check token.TokenType) bool {
	if p.position >= len(p.tokens) {
		return true
	}
	return p.tokens[p.position].Type == check
}

// æ‰“å°å‰©ä½™çš„
func (p *Parser) printRemaining() {
	for !p.isEOF() {
		fmt.Println(p.current().Literal)
		p.next()
	}
}

func (p *Parser) GetVariables() []data.Variable {
	return p.scopeManager.CurrentScope().GetVariables()
}

// next ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªè¯æ³•å•å…ƒ
func (p *Parser) next() {
	p.position++
}

func (p *Parser) nextAndCheck(t token.TokenType) data.Control {
	if p.current().Type != t {
		err := fmt.Errorf("æ£€æŸ¥ç¬¦å·ä¸ä¸€è‡´, éœ€è¦(%v:%v), å½“å‰(%v:%v)", t, token.GetLiteralByType(t), p.current().Type, p.current().Literal)
		return data.NewErrorThrow(p.newFrom(), err)
	}
	p.position++
	return nil
}

func (p *Parser) nextAndCheckStip(t token.TokenType) {
	if p.current().Type == t {
		p.position++
	}
}

// isEOF æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ–‡ä»¶æœ«å°¾
func (p *Parser) isEOF() bool {
	return p.position >= len(p.tokens)
}

func (p *Parser) addControl(acl data.Control) {
	p.vm.ThrowControl(acl)
}

// ç»“æŸå½“å‰æ–‡ä»¶è§£æ
func (p *Parser) stopNext() {
	p.position = len(p.tokens)
}

func (p *Parser) ShowControl(acl data.Control) {
	err := acl.AsString()

	// ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ ThrowValue å¹¶æ˜¾ç¤ºè°ƒç”¨æ ˆ
	if throwValue, ok := acl.(*data.ThrowValue); ok {
		from := throwValue.Error.From
		if from == nil {
			from = node.NewTokenFrom(p.source, p.current().Start, p.current().End, p.current().Line, p.current().Pos)
		}
		p.errors = append(p.errors, data.NewErrorThrow(from, errors.New(err)))

		// æ˜¾ç¤ºè°ƒç”¨æ ˆä¿¡æ¯
		if len(throwValue.StackFrames) > 0 {
			_, _ = fmt.Fprintln(os.Stderr, "\nğŸ“š è°ƒç”¨æ ˆ:")
			for i, frame := range throwValue.StackFrames {
				stackStart, stackEnd := frame.From.GetPosition()
				stackSl, stackSp := frame.From.GetStartPosition()
				_, _ = fmt.Fprintf(os.Stderr, "   %d. %s::%s() at %s:%d:%d (ä½ç½®: %d-%d)\n",
					i+1, frame.ClassName, frame.MethodName, frame.From.GetSource(), stackSl+1, stackSp+1, stackStart, stackEnd)
			}
		}

		// æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
		p.printDetailedError(err, from)
	} else if acl, ok := acl.(node.GetFrom); ok {
		from := acl.GetFrom()
		p.errors = append(p.errors, data.NewErrorThrow(from, errors.New(err)))
		// æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
		p.printDetailedError(err, from)
	} else {
		from := node.NewTokenFrom(p.source, p.current().Start, p.current().End, p.current().Line, p.current().Pos)
		p.errors = append(p.errors, data.NewErrorThrow(from, errors.New(err)))
		// æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
		p.printDetailedError(err, from)
	}
}

func (p *Parser) GetStart() int {
	return p.current().Start
}

// Deprecated: ä½¿ç”¨ NewFromBuilder() æˆ–å…¶ä»–æ–°æ–¹æ³•æ›¿ä»£
func (p *Parser) NewTokenFrom(start int) *node.TokenFrom {
	return node.NewTokenFrom(p.source, start, p.current().End, p.current().Line, p.current().Pos)
}

// StartPosition å¼€å§‹ä½ç½®è·Ÿè¸ªï¼Œè¿”å›å½“å‰ä½ç½®
func (p *Parser) StartPosition() int {
	return p.position
}

// EndPosition ç»“æŸä½ç½®è·Ÿè¸ªï¼Œè¿”å›å½“å‰ä½ç½®
func (p *Parser) EndPosition() int {
	return p.position
}

// FromPositionRange ä»ä½ç½®èŒƒå›´åˆ›å»ºFromä¿¡æ¯
func (p *Parser) FromPositionRange(startPos, endPos int) *node.TokenFrom {
	if startPos >= len(p.tokens) || endPos >= len(p.tokens) {
		return p.FromCurrentToken()
	}

	startToken := p.tokens[startPos]
	endToken := p.tokens[endPos]

	// åˆ›å»º TokenFrom å¹¶è®¾ç½®ç»“æŸä½ç½®
	tf := node.NewTokenFrom(p.source, startToken.Start, endToken.End, startToken.Line, startToken.Pos)

	// æ€»æ˜¯è®¾ç½®ç»“æŸä½ç½®ï¼Œç¡®ä¿ä½ç½®ä¿¡æ¯å®Œæ•´
	// å³ä½¿ startPos == endPosï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦æ­£ç¡®çš„ç»“æŸä½ç½®ä¿¡æ¯
	tf.SetEndPosition(endToken.Line, endToken.Pos)

	return tf
}

// isTokensAdjacent æ£€æŸ¥ä¸¤ä¸ª token æ˜¯å¦ç›¸é‚»ï¼ˆæ²¡æœ‰ç©ºç™½å­—ç¬¦æˆ–å…¶ä»–åˆ†éš”ç¬¦ï¼‰
func (p *Parser) isTokensAdjacent(token1, token2 lexer.Token) bool {
	// å¦‚æœç¬¬ä¸€ä¸ª token çš„ç»“æŸä½ç½®ç­‰äºç¬¬äºŒä¸ª token çš„å¼€å§‹ä½ç½®ï¼Œè¯´æ˜å®ƒä»¬æ˜¯ç›¸é‚»çš„
	return token1.End == token2.Start
}

func (p *Parser) checkClassName(name string) {

}

// è·å–ç±»çš„å®Œæ•´è·¯å¾„, ç±»å®šä¹‰è‡ªå·±ä¸ç”¨, ä½†æ˜¯ç»§æ‰¿ã€å®ç°æ¥å£éœ€è¦è°ƒç”¨
func (p *Parser) getClassName(try bool) (string, data.Control) {
	className := p.current().Literal
	p.next()

	if strings.Index(className, "\\") == -1 {
		// å¦‚æœåªæœ‰ä¸€ä¸ªå•è¯, åˆ™è®¤ä¸ºå¯èƒ½æ˜¯åˆ«å
		if full, ok := p.uses[className]; ok {
			return full, nil
		}
		// ä¹Ÿæœ‰å¯èƒ½æ˜¯åŒä¸€ä¸ªåŒ…å†…çš„ç±»
		if try {
			if full, ok := p.findFullClassNameByNamespace(className); ok {
				return full, nil
			}
		}
	}

	return className, nil
}

// parseStatement è§£æè¯­å¥
func (p *Parser) parseStatement() (data.GetValue, data.Control) {
	return p.expressionParser.Parse()
}

// åªä¼šè·å–å•ä¸ªå€¼, ä¸ä¼šæœ‰è¡¨è¾¾å¼, å¹¶ä¸”å¿…é¡»æœ‰å€¼, æ²¡æœ‰å°±æ˜¯é”™è¯¯
func (p *Parser) parseValue() (data.GetValue, bool) {
	tracker := p.StartTracking()
	switch p.current().Type {
	case token.INT:
		value := p.current().Literal
		p.next()
		return node.NewIntLiteral(tracker.EndBefore(), value), true
	case token.FLOAT:
		value := p.current().Literal
		p.next()
		return node.NewFloatLiteral(tracker.EndBefore(), value), true
	case token.STRING:
		value := p.current().Literal
		p.next()
		return node.NewStringLiteral(tracker.EndBefore(), value), true
	case token.TRUE:
		p.next()
		return node.NewBooleanLiteral(tracker.EndBefore(), true), true
	case token.FALSE:
		p.next()
		return node.NewBooleanLiteral(tracker.EndBefore(), false), true
	case token.NULL:
		p.next()
		return node.NewNullLiteral(tracker.EndBefore()), true
	case token.THIS:
		stmt, acl := NewThisParser(p).Parse()
		_ = acl
		return stmt, true
	case token.VARIABLE:
		vp := &VariableParser{p}
		return vp.parseVariable(), true
	case token.IDENTIFIER:
		vp := &VariableParser{p}
		return vp.parseVariable(), true
	default:
		return nil, false
	}
}

// parseBlock è§£æè¯­å¥å—
func (p *Parser) parseBlock() ([]data.GetValue, data.Control) {
	statements := make([]data.GetValue, 0)

	// æ£€æŸ¥æ˜¯å¦æ˜¯è¯­å¥å—å¼€å§‹
	if p.current().Type != token.LBRACE {
		// å¦‚æœä¸æ˜¯è¯­å¥å—ï¼Œåˆ™è§£æå•ä¸ªè¯­å¥
		stmt, acl := p.parseStatement()
		if acl != nil {
			return nil, acl
		}
		if stmt != nil {
			statements = append(statements, stmt)
		}
		return statements, nil
	}

	// è·³è¿‡å·¦èŠ±æ‹¬å·
	p.next()

	for p.checkPositionIs(0, token.SEMICOLON) {
		p.next()
	}

	// è§£æè¯­å¥å—ä¸­çš„æ‰€æœ‰è¯­å¥
	for !p.isEOF() && p.current().Type != token.RBRACE {
		stmt, acl := p.parseStatement()
		if acl != nil {
			return nil, acl
		}
		for p.checkPositionIs(0, token.SEMICOLON) {
			p.next()
		}
		if stmt != nil {
			statements = append(statements, stmt)
		} else {
			return statements, data.NewErrorThrow(p.newFrom(), errors.New("è¯­æ³•å—æ— æ³•è¯†åˆ«"))
		}
	}

	// è·³è¿‡å³èŠ±æ‹¬å·
	p.nextAndCheck(token.RBRACE)

	return statements, nil
}

func (p *Parser) AddScanNamespace(namespace string, path string) {
	// ä½¿ç”¨ç±»è·¯å¾„ç®¡ç†å™¨æ·»åŠ å‘½åç©ºé—´
	p.classPathManager.AddNamespace(namespace, path)
}

// é»˜è®¤ try = true
func (p *Parser) findFullClassNameByNamespace(name string, try ...bool) (string, bool) {
	tryName := name

	if full, ok := p.uses[name]; ok {
		return full, true
	}

	if p.namespace != nil {
		tryName = p.namespace.GetName() + "\\" + name
	}
	// æœ¬åŒ…
	if stmt, ok := p.vm.GetClass(tryName); ok {
		return stmt.GetName(), true
	}
	if stmt, ok := p.vm.GetInterface(tryName); ok {
		return stmt.GetName(), true
	}
	if _, ok := p.vm.GetClassPathCache(tryName); ok {
		return tryName, true
	}
	// é¡¶å‘½å
	if stmt, ok := p.vm.GetClass(name); ok {
		return stmt.GetName(), true
	}
	if stmt, ok := p.vm.GetInterface(name); ok {
		return stmt.GetName(), true
	}

	if len(try) > 0 && !try[0] {
		return "", false
	}

	// å°è¯•åŠ è½½åŒç›®å½•çš„åŒåæ–‡ä»¶
	p.tryLoadClass(tryName)

	// åŠ è½½æˆåŠŸï¼Œå†æ¬¡å°è¯•æŸ¥æ‰¾ç±»
	if full, ok := p.findFullClassNameByNamespace(name, false); ok {
		return full, true
	}
	return "", false
}

func (p *Parser) findFullFunNameByNamespace(name string) (string, bool) {
	if full, ok := p.uses[name]; ok {
		return full, true
	}
	tryName := name
	if p.namespace != nil && strings.Index(name, "\\") == -1 {
		tryName = p.namespace.GetName() + "\\" + name
	}
	if stmt, ok := p.vm.GetFunc(tryName); ok {
		return stmt.GetName(), true
	}
	if stmt, ok := p.vm.GetFunc(name); ok {
		return stmt.GetName(), true
	}

	return "", false
}

func (p *Parser) newFrom() data.From {
	return p.FromCurrentToken()
}

// å°è¯•åŠ è½½ç±»
func (p *Parser) tryLoadClass(full string) data.Control {
	if _, ok := p.vm.GetClass(full); ok {
		return nil
	}
	if _, ok := p.vm.GetInterface(full); ok {
		return nil
	}

	// ä½¿ç”¨ç±»è·¯å¾„ç®¡ç†å™¨åŠ è½½ç±»
	return p.classPathManager.LoadClass(full, p)
}

// SetClassPathManager è®¾ç½®ç±»è·¯å¾„ç®¡ç†å™¨
func (p *Parser) SetClassPathManager(manager ClassPathManager) {
	p.classPathManager = manager
}

// GetClassPathManager è·å–ç±»è·¯å¾„ç®¡ç†å™¨
func (p *Parser) GetClassPathManager() ClassPathManager {
	return p.classPathManager
}

// ParseExpressionFromString ä»å­—ç¬¦ä¸²è§£æè¡¨è¾¾å¼
func (p *Parser) ParseExpressionFromString(exprStr string) (data.GetValue, data.Control) {
	// ä¿å­˜å½“å‰çŠ¶æ€
	originalTokens := p.tokens
	originalPosition := p.position

	// é‡ç½®è§£æå™¨çŠ¶æ€
	p.tokens = make([]lexer.Token, 0)
	p.position = 0

	// å¯¹è¡¨è¾¾å¼å­—ç¬¦ä¸²è¿›è¡Œåˆ†è¯
	p.tokens = p.lexer.Tokenize(exprStr)

	// ä½¿ç”¨è¡¨è¾¾å¼è§£æå™¨è§£æ
	exprParser := NewExpressionParser(p)
	result, ctl := exprParser.Parse()

	// æ¢å¤åŸå§‹çŠ¶æ€
	p.tokens = originalTokens
	p.position = originalPosition

	return result, ctl
}

// ParserTokens ä¼ å…¥ token åˆ—è¡¨é‡æ–°è¿è¡Œ
func (p *Parser) ParserTokens(tokens []lexer.Token, filePath string) (*node.Program, data.Control) {
	if len(tokens) > 1 && tokens[0].Type == token.SEMICOLON {
		nTokens := make([]lexer.Token, 0)
		i := 0
		for tokens[i].Type == token.SEMICOLON {
			i++
		}
		for _, t := range tokens[i:] {
			nTokens = append(nTokens, t)
		}
		tokens = nTokens
	}

	// ä¿å­˜å½“å‰çŠ¶æ€
	originalTokens := p.tokens
	originalPosition := p.position
	originalSource := p.source

	// é‡ç½®è§£æå™¨çŠ¶æ€
	p.reset()

	// è®¾ç½®æºæ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿ç¬¦å·ä½ç½®ä¿¡æ¯æ­£ç¡®
	p.source = &filePath

	// è¿›è¡Œåˆ†è¯
	p.tokens = tokens

	// è§£æç¨‹åº
	program, acl := p.parseProgram()
	if acl != nil {
		return nil, acl
	}

	// æ¢å¤åŸå§‹çŠ¶æ€
	p.tokens = originalTokens
	p.position = originalPosition
	p.source = originalSource

	return program, nil
}

// ParseString ä»å­—ç¬¦ä¸²è§£æç¨‹åº
func (p *Parser) ParseString(content string, filePath string) (*node.Program, data.Control) {
	// ä¿å­˜å½“å‰çŠ¶æ€
	originalTokens := p.tokens
	originalPosition := p.position
	originalSource := p.source

	// é‡ç½®è§£æå™¨çŠ¶æ€
	p.reset()

	// è®¾ç½®æºæ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿ç¬¦å·ä½ç½®ä¿¡æ¯æ­£ç¡®
	p.source = &filePath

	// è¿›è¡Œåˆ†è¯
	p.tokens = p.lexer.Tokenize(content)

	// è§£æç¨‹åº
	program, acl := p.parseProgram()
	if acl != nil {
		return nil, acl
	}

	// æ¢å¤åŸå§‹çŠ¶æ€
	p.tokens = originalTokens
	p.position = originalPosition
	p.source = originalSource

	return program, nil
}

// å°è¯•è¯†åˆ«ç±»å‹
func (p *Parser) tryFindTypes() (data.Types, bool) {
	if data.ISBaseType(p.current().Literal) {
		return data.NewBaseType(p.current().Literal), true
	}

	name, ok := p.findFullClassNameByNamespace(p.current().Literal)
	if ok {
		return data.NewBaseType(name), true
	}
	return nil, false
}
